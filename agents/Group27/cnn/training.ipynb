{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(Path().resolve() / 'agents/Group27/mcts')\n",
    "if (path not in sys.path):\n",
    "    sys.path.append(path)\n",
    "\n",
    "from PolicyModel import PolicyModel\n",
    "from HeuristicModel import HeuristicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = input()\n",
    "if (modelName == ''):\n",
    "    modelName = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5998\n",
      "105501\n"
     ]
    }
   ],
   "source": [
    "def loadData(dataFile):\n",
    "    path = str(Path().resolve())\n",
    "    with open(os.path.join(path, '..', 'data', f'{dataFile}.json'), 'rb') as f:\n",
    "        rawData = json.load(f)\n",
    "    print(len(rawData))\n",
    "    return rawData\n",
    "\n",
    "rawExpertData = loadData('expert-v-expert')\n",
    "rawSelfPlayData = loadData('chump-v-chump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 \n",
      " 0 0 0 0 0 0 0 0 0 0 0 \n",
      "  0 0 0 0 0 0 0 0 0 0 0 \n",
      "   0 0 0 0 0 0 0 0 0 0 0 \n",
      "    0 0 0 0 0 0 0 0 0 0 0 \n",
      "     0 0 0 0 0 0 0 0 0 0 0 \n",
      "      0 0 0 0 0 0 0 0 0 0 0 \n",
      "       0 0 0 0 0 0 0 0 0 0 0 \n",
      "        0 0 0 0 0 0 0 0 0 0 0 \n",
      "         0 0 0 0 0 0 0 0 0 0 0 \n",
      "          0 0 0 0 0 0 0 0 0 0 0 \n",
      "\n",
      "[[6, 8, 9, 8, 7, 8, 8, 5, 6, 7, 12], [6, 5, 7, 9, 8, 3, 13, 10, 10, 8, 10], [9, 8, 11, 5, 11, 12, 10, 8, 11, 8, 10], [5, 9, 6, 7, 7, 13, 4, 7, 8, 10, 9], [8, 6, 7, 6, 10, 6, 6, 13, 12, 8, 6], [4, 10, 10, 6, 12, 6, 11, 7, 4, 8, 9], [5, 8, 7, 5, 5, 14, 9, 13, 9, 19, 6], [15, 6, 7, 9, 10, 12, 11, 7, 6, 7, 8], [10, 7, 6, 9, 2, 12, 4, 12, 10, 6, 5], [7, 5, 10, 10, 9, 8, 9, 6, 7, 9, 12], [12, 11, 11, 7, 2, 6, 8, 10, 7, 7, 10]]\n"
     ]
    }
   ],
   "source": [
    "for item in rawSelfPlayData.items():\n",
    "    print(item[0])\n",
    "    tempMoves = item[1]['moves']\n",
    "    print(tempMoves)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempBoard = \"R 0 0 0 R B 0 0 B R 0 \\n R 0 B 0 0 B R B 0 R B \\n  B 0 R 0 R R B 0 B R 0 \\n   0 0 0 0 0 B 0 R 0 B 0 \\n    B R 0 0 B R B R R R R \\n     R B B B 0 0 R B 0 0 R \\n      B R 0 R 0 R R B R B 0 \\n       B R R B R B B B 0 R R \\n        B R 0 0 B 0 0 0 R B 0 \\n         0 B R B B B R B B 0 R \\n          B 0 0 0 0 B R B R R R \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "         [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "         [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "         [0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "         [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1],\n",
       "         [0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       "         [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "         [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tensorfyBoard(boardString):\n",
    "    boardString = boardString.replace('R', '1').replace('B', '2')\n",
    "    boardRows = boardString.strip().split('\\n')\n",
    "    board = [list(map(int, row.strip().split())) for row in boardRows]\n",
    "\n",
    "    board = torch.tensor(board, dtype=torch.int)\n",
    "\n",
    "    rStones = (board == 1).int()\n",
    "    bStones = (board == 2).int()\n",
    "    nStones = (board == 0).int()\n",
    "\n",
    "    return torch.stack([rStones, bStones, nStones])\n",
    "\n",
    "tensorfyBoard(tempBoard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0057, 0.0086, 0.0096, 0.0086, 0.0067, 0.0077, 0.0086, 0.0057, 0.0057,\n",
       "        0.0067, 0.0125, 0.0057, 0.0057, 0.0067, 0.0096, 0.0086, 0.0029, 0.0125,\n",
       "        0.0096, 0.0105, 0.0077, 0.0096, 0.0086, 0.0086, 0.0105, 0.0057, 0.0105,\n",
       "        0.0115, 0.0096, 0.0086, 0.0105, 0.0077, 0.0105, 0.0057, 0.0096, 0.0067,\n",
       "        0.0077, 0.0077, 0.0125, 0.0048, 0.0067, 0.0086, 0.0096, 0.0096, 0.0077,\n",
       "        0.0057, 0.0077, 0.0067, 0.0096, 0.0057, 0.0057, 0.0125, 0.0115, 0.0077,\n",
       "        0.0057, 0.0038, 0.0096, 0.0096, 0.0057, 0.0125, 0.0067, 0.0105, 0.0067,\n",
       "        0.0048, 0.0086, 0.0086, 0.0048, 0.0077, 0.0077, 0.0048, 0.0057, 0.0134,\n",
       "        0.0086, 0.0125, 0.0086, 0.0182, 0.0067, 0.0144, 0.0057, 0.0067, 0.0086,\n",
       "        0.0096, 0.0115, 0.0105, 0.0067, 0.0067, 0.0067, 0.0077, 0.0096, 0.0067,\n",
       "        0.0067, 0.0096, 0.0019, 0.0125, 0.0048, 0.0125, 0.0096, 0.0057, 0.0057,\n",
       "        0.0077, 0.0048, 0.0096, 0.0096, 0.0086, 0.0077, 0.0086, 0.0057, 0.0067,\n",
       "        0.0096, 0.0115, 0.0115, 0.0115, 0.0115, 0.0077, 0.0029, 0.0057, 0.0077,\n",
       "        0.0096, 0.0067, 0.0067, 0.0096])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encodeMoves(moves2D, boardTensor):\n",
    "    moves = torch.tensor(np.array(moves2D).flatten())\n",
    "\n",
    "    # smoothing\n",
    "    moves += boardTensor[2].flatten()\n",
    "\n",
    "    # normalise\n",
    "    moves = moves / moves.sum()\n",
    "    return moves\n",
    "\n",
    "encodeMoves(tempMoves, tensorfyBoard(tempBoard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5998, 3, 11, 11]) torch.Size([5998, 121]) torch.Size([5998])\n",
      "torch.Size([105501, 3, 11, 11]) torch.Size([105501, 121]) torch.Size([105501])\n"
     ]
    }
   ],
   "source": [
    "def processDataSet(dataSet):\n",
    "    boardTensors = []\n",
    "    moveTensors = []\n",
    "    payoffTensors = []\n",
    "\n",
    "    for (boardString, data) in dataSet.items():\n",
    "        boardTensor = tensorfyBoard(boardString)\n",
    "        moveTensor = encodeMoves(data['moves'], boardTensor)\n",
    "\n",
    "        boardTensors.append(boardTensor)\n",
    "        moveTensors.append(moveTensor)\n",
    "        payoffTensors.append(torch.tensor(data['payoff']))\n",
    "\n",
    "    boards = torch.stack(boardTensors)\n",
    "    moves = torch.stack(moveTensors)\n",
    "    payoffs = torch.stack(payoffTensors)\n",
    "\n",
    "    return boards, moves, payoffs\n",
    "\n",
    "expertBoards, expertMoves, expertPayoffs = processDataSet(rawExpertData)\n",
    "print(expertBoards.shape, expertMoves.shape, expertPayoffs.shape)\n",
    "selfPlayBoards, selfPlayMoves, selfPlayPayoffs = processDataSet(rawSelfPlayData)\n",
    "print(selfPlayBoards.shape, selfPlayMoves.shape, selfPlayPayoffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "The Hex board is symmetric. We can use this to augment our data. For each board state, we can generate 6 more board states by rotating the board by 60 degrees each time. This will give us 7 times more data to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Model\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policyModel = PolicyModel(boardSize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERT\n",
      "Epoch 1: 0.1506\n",
      "Epoch 2: 0.1469\n",
      "Epoch 3: 0.1472\n",
      "Epoch 4: 0.1465\n",
      "Epoch 5: 0.1469\n",
      "Epoch 6: 0.1465\n",
      "Epoch 7: 0.1468\n",
      "Epoch 8: 0.1469\n",
      "Epoch 9: 0.1470\n",
      "Epoch 10: 0.1468\n",
      "SELF-PLAY\n",
      "Epoch 1: 0.7738\n",
      "Epoch 2: 0.7706\n",
      "Epoch 3: 0.7708\n",
      "Epoch 4: 0.7704\n",
      "Epoch 5: 0.7705\n",
      "Epoch 6: 0.7709\n",
      "Epoch 7: 0.7707\n",
      "Epoch 8: 0.7709\n",
      "Epoch 9: 0.7709\n",
      "Epoch 10: 0.7706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PolicyModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convp): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fcp): Linear(in_features=242, out_features=121, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainModel(model, criterion, boards, expected, softmax, batchSize=256, learningRate=1e-3, epochs=10):\n",
    "\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "\n",
    "    dataset = TensorDataset(boards, expected)\n",
    "    dataLoader = DataLoader(dataset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epochLoss = 0.0\n",
    "        for batchBoards, batchExpected in dataLoader:\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            logits = model(batchBoards)\n",
    "            if softmax:\n",
    "                predictions = torch.nn.functional.log_softmax(logits, dim=1)\n",
    "            else:\n",
    "                predictions = logits.squeeze(1)\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(predictions, batchExpected)\n",
    "            epochLoss += loss.item()\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}: {epochLoss/len(dataLoader):.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# train on expert moves\n",
    "print('EXPERT')\n",
    "trainModel(policyModel, criterion, expertBoards.float(), expertMoves, softmax=True, learningRate=1e-2)\n",
    "# train on self-play moves\n",
    "print('SELF-PLAY')\n",
    "trainModel(policyModel, criterion, selfPlayBoards.float(), selfPlayMoves, softmax=True, learningRate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0080, 0.0081, 0.0083, 0.0084, 0.0081, 0.0084, 0.0081, 0.0085, 0.0077,\n",
       "         0.0082, 0.0081, 0.0083, 0.0084, 0.0083, 0.0083, 0.0083, 0.0080, 0.0083,\n",
       "         0.0086, 0.0084, 0.0082, 0.0080, 0.0078, 0.0082, 0.0081, 0.0086, 0.0082,\n",
       "         0.0086, 0.0081, 0.0080, 0.0085, 0.0082, 0.0084, 0.0082, 0.0084, 0.0082,\n",
       "         0.0085, 0.0080, 0.0081, 0.0086, 0.0082, 0.0081, 0.0082, 0.0085, 0.0082,\n",
       "         0.0083, 0.0083, 0.0083, 0.0087, 0.0079, 0.0080, 0.0084, 0.0082, 0.0081,\n",
       "         0.0083, 0.0084, 0.0079, 0.0080, 0.0085, 0.0079, 0.0083, 0.0079, 0.0083,\n",
       "         0.0085, 0.0077, 0.0080, 0.0082, 0.0086, 0.0080, 0.0082, 0.0081, 0.0083,\n",
       "         0.0084, 0.0083, 0.0080, 0.0081, 0.0085, 0.0083, 0.0084, 0.0085, 0.0084,\n",
       "         0.0083, 0.0086, 0.0085, 0.0084, 0.0085, 0.0082, 0.0078, 0.0087, 0.0079,\n",
       "         0.0084, 0.0082, 0.0085, 0.0082, 0.0085, 0.0083, 0.0083, 0.0086, 0.0082,\n",
       "         0.0083, 0.0083, 0.0081, 0.0084, 0.0080, 0.0089, 0.0080, 0.0083, 0.0082,\n",
       "         0.0085, 0.0085, 0.0080, 0.0086, 0.0086, 0.0081, 0.0081, 0.0082, 0.0088,\n",
       "         0.0084, 0.0082, 0.0082, 0.0081]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(model, boardString):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        boardTensor = tensorfyBoard(boardString)\n",
    "        logits = model(boardTensor.float().unsqueeze(0))\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "    return probs\n",
    "\n",
    "infer(policyModel, tempBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policyModel.state_dict(), f'./models/{modelName}_policy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristicModel = HeuristicModel(boardSize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERT\n",
      "Epoch 1: 1.1217\n",
      "Epoch 2: 1.1213\n",
      "Epoch 3: 1.1240\n",
      "Epoch 4: 1.1201\n",
      "Epoch 5: 1.1229\n",
      "Epoch 6: 1.1215\n",
      "Epoch 7: 1.1253\n",
      "Epoch 8: 1.1229\n",
      "Epoch 9: 1.1235\n",
      "Epoch 10: 1.1206\n",
      "SELF-PLAY\n",
      "Epoch 1: 1.0634\n",
      "Epoch 2: 1.0619\n",
      "Epoch 3: 1.0618\n",
      "Epoch 4: 1.0619\n",
      "Epoch 5: 1.0624\n",
      "Epoch 6: 1.0629\n",
      "Epoch 7: 1.0618\n",
      "Epoch 8: 1.0618\n",
      "Epoch 9: 1.0619\n",
      "Epoch 10: 1.0618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeuristicModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convh): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fch): Linear(in_features=242, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# train on expert moves\n",
    "print('EXPERT')\n",
    "trainModel(heuristicModel, criterion, expertBoards.float(), expertPayoffs.float(), softmax=False, batchSize=256, learningRate=1e-2)\n",
    "# train on self-play moves\n",
    "print('SELF-PLAY')\n",
    "trainModel(heuristicModel, criterion, selfPlayBoards.float(), selfPlayPayoffs.float(), softmax=False, batchSize=256, learningRate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(heuristicModel, tempBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(heuristicModel.state_dict(), f'./models/{modelName}_heuristic.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
